{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 정렬및 임시저장\n",
    "# temp1.sort_values(by=['opening_date', 'title_kor'], ascending=False, na_position='first', inplace=True, ignore_index=True)\n",
    "# temp2.sort_values(by=['opening_date', 'title_kor'], ascending=False, na_position='first', inplace=True, ignore_index=True)\n",
    "# temp3.sort_values(by=['opening_date', 'title_kor'], ascending=False, na_position='first', inplace=True, ignore_index=True)\n",
    "# temp4.sort_values(by=['opening_date', 'title_kor'], ascending=False, na_position='first', inplace=True, ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sig 쓰면 엑셀에서 읽어지는데 왜 sig 일까\n",
    "# temp1.to_csv(r'./0330wavve.csv', index=False, encoding='utf-8-sig') \n",
    "# temp2.to_csv(r'./0330watcha.csv', index=False, encoding='utf-8-sig')\n",
    "# temp3.to_csv(r'./0330netflix.csv', index=False, encoding='utf-8-sig')\n",
    "# temp4.to_csv(r'./0330disney.csv', index=False, encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0. 임시저장 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp1= pd.read_csv(r'./0330wavve.csv') \n",
    "temp2= pd.read_csv(r'./0330watcha.csv')\n",
    "temp3= pd.read_csv(r'./0330netflix.csv')\n",
    "temp4= pd.read_csv(r'./0330disney.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10650, 5562, 3270, 967)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(temp1), len(temp2), len(temp3), len(temp4)\n",
    "# (10651, 5564, 3270, 968)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 진행경과\n",
    "\n",
    "    정렬. 컬럼통일, 매핑되어있는것 확인, \n",
    "\n",
    "- 이후 진행은 \n",
    "\n",
    "    포스터 링크 키값가능한지 확인 후 머지."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14, 14, 14, 14)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(temp1.columns), len(temp2.columns), len(temp3.columns), len(temp4.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10651, 5564, 3270, 968)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(temp1), len(temp2), len(temp3), len(temp4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "title_kor       10506\n",
       "opening_date       90\n",
       "just_rating        83\n",
       "imdb_rating       157\n",
       "runtime           190\n",
       "synopsis        10645\n",
       "director         6541\n",
       "actors          10211\n",
       "genre            2826\n",
       "posterLink      10651\n",
       "netflix             1\n",
       "disney              1\n",
       "wavve               1\n",
       "watcha              1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp1.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "968"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp1.posterLink.nunique() # 10651 1개어디.\n",
    "temp2.posterLink.nunique() #  5564 2개어디?\n",
    "temp3.posterLink.nunique() # 3270 유니크\n",
    "temp4.posterLink.nunique() # 968  1개 어디?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 엑셀에서 중복값 확인후 처리 해볼것"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['판다를 안아줘!: 메이의 새빨간 비밀 비하인드', 2022, '79%', ..., 1, 0, 0],\n",
       "       ['클로틸다: 미국의 마지막 노예선', 2022, '65%', ..., 1, 0, 0],\n",
       "       ['메이의 새빨간 비밀', 2022, '85%', ..., 1, 0, 0],\n",
       "       ...,\n",
       "       ['아기 돼지 삼형제', 1933, '74%', ..., 1, 0, 0],\n",
       "       ['Flowers and Trees', 1932, '73%', ..., 1, 0, 0],\n",
       "       ['증기선 윌리', 1928, '80%', ..., 1, 0, 0]], dtype=object)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 디즈니\n",
    "\n",
    "# Heavy Metal Mater 2010\n",
    "# Unidentified Flying Mater 2009 \n",
    "# 같은영화인데 정보달리해서 중복으로 들어가 있음. 확인. \n",
    "\n",
    "# Unidentified Flying Mater 2009 드랍할것. \n",
    "temp4.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "967"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.where(temp4.values == 'Heavy Metal Mater') # 인덱스 475행\n",
    "np.where(temp4.values == 'Unidentified Flying Mater') # 인덱스 506행\n",
    "temp4 = temp4.drop(506)\n",
    "len(temp4) # 968"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10650"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# temp1.posterLink.nunique() # 10651 1개어디.\n",
    "# 다큐 빅 브라더 2018년 \n",
    "# 액션스릴러 헌터스 프레어 2017 겹쳐. \n",
    "# 포스터 링크는 헌터스 프레어로 연결되므로 빅 브라더 드랍. \n",
    "\n",
    "np.where(temp1.values == '빅 브라더') #인덱스 2681\n",
    "# temp1 = temp1.drop(2681)\n",
    "len(temp1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['빅샤크2: 해저2만리', 2018, nan, nan, '1시간16분',\n",
       "       \"세계명작 '해저2만리' 속으로 떠나는 빅샤크와 바닷속 친구들의 짜릿한 대모험! 평화롭던 바다 왕국. 어느 날, 정체불명의 해저몬스터가 출몰해 화물선을 잇달아 파괴하며 바다왕국을 온통 공포로 몰아넣는다. 용감한 아기상어 메이와 바닷속 친구들은 몬스터를 잡기 위해 동화 속 해저2만리로 탐험을 떠나기로 한다. 하지만 탐험을 시작하기도 전에 메이가 그만 해저몬스터에게 납치되고 마는데… 아빠상어 빅샤크와 꼬마잠수함 올리와 베스, 수달 보보, 그리고 해마친구들은 위험에 빠진 아기상어를 구하기 위해 깊은 바다 밑 해저 2만리 속으로 신비하고도 짜릿한 모험을 시작한다!\",\n",
       "       nan, 'ChurongFan,HongHaitian', '액션,애니메이션',\n",
       "       'https://images.justwatch.com/poster/117938149/s592', 0, 0, 1, 0],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp1.values[2680]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([], dtype=int64), array([], dtype=int64))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.where(temp1.values == '빅 브라더') # 없음. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5562"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(temp2), temp2.posterLink.nunique() # 2r개 찾기. \n",
    "# 사랑과 영혼: 헬로우 고스트  영화가 2개. 1개 드랍 하고\n",
    "# 빅 브라더 라는 중국 이상한 코미디 영화. 드랍. \n",
    "\n",
    "np.where(temp2.values == '사랑과 영혼: 헬로우 고스트')  # 1343, 1344 2개 있어.\n",
    "# np.where(temp2.values == '빅 브라더') #1352\n",
    "temp2 = temp2.drop(1344)\n",
    "temp2 = temp2.drop(1352)\n",
    "len(temp2) # 5566 - 2 = 5564"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.where(temp2.values == '사랑과 영혼: 헬로우 고스트')\n",
    "# np.where(temp2.values == '빅 브라더') # 결과없음."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# temp3 는 포스터 링크 유니크."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 인덱스 정렬 \n",
    "temp1.reset_index(inplace=True, drop=True)\n",
    "temp2.reset_index(inplace=True, drop=True)\n",
    "temp3.reset_index(inplace=True, drop=True)\n",
    "temp4.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1 = pd.merge(temp3, temp4, on=['title_kor', 'opening_date', 'posterLink'], how='inner')\n",
    "t1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title_list = t1.title_kor.values\n",
    "title_list, type(title_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(np.where(title_list == '나를 찾아줘')[0][0])\n",
    "np.where(title_list == '나를 찾아줘',)\n",
    "# np.where('나를 찾아줘')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# duplication_list = []\n",
    "# for i,v in enumerate(title_list):\n",
    "#     where_index = np.where(title_list == title_list[i])[0]\n",
    "#     print(i, v, where_index)\n",
    "#     # print(v)\n",
    "#     duplication_list.append(where_index)\n",
    "\n",
    "# len(duplication_list)\n",
    "# type(i), type(v)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# temp3['disney'][1] = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for t in title_list:\n",
    "    v = np.where(temp3.title_kor==t)[0][0]\n",
    "    temp3['disney'][v] = 1\n",
    "    print(t, v)\n",
    "sum(temp3.disney)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(temp3), len(temp4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_concat = pd.concat([temp3, temp4], ignore_index=True, axis=0)\n",
    "len(dt_concat) # 4238 = 3270 + 968"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_concat.nunique() \n",
    "# 포스터링크 4234 . 4개 공통이었으므로 맞는 값임.\n",
    "# 넷플, 디즈니 매핑됐으니. 각 유니크값은 0, 1 로 두개씩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(dt_concat)\n",
    "list(map(sum, [dt_concat.wavve, dt_concat.watcha, dt_concat.netflix, dt_concat.disney]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 드랍. 넷플에 디즈니 매핑 후 공통된 값 드랍.\n",
    "dt_concat.drop_duplicates(subset=['title_kor', 'opening_date', 'posterLink'], inplace=True)\n",
    "len(dt_concat), len(t1), len(temp3), len(temp4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(dt_concat)\n",
    "list(map(sum, [dt_concat.wavve, dt_concat.watcha, dt_concat.netflix, dt_concat.disney]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 컨캣 dt와  왓챠(temp2) 붙이고 중복제거."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_concat.reset_index(drop=True, inplace=True)\n",
    "# dt_concat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t2 = pd.merge(dt_concat, temp2, on=['title_kor','opening_date','posterLink'], how='inner')\n",
    "len(t2) # 공통영화 574"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title_list = t2.title_kor.values\n",
    "title_list, type(title_list), len(title_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t2[t2.title_kor.duplicated() == True]  # 같은 제목 하나 있음. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.where(title_list == '너의 췌장을 먹고 싶어')[0].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.where(dt_concat.title_kor=='침입자')[0].tolist()\n",
    "# np.where(dt_concat.title_kor=='히트맨')[0].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(np.where(dt_concat.title_kor=='침입자')[0].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 0\n",
    "m = 0\n",
    "for t in title_list:\n",
    "    v = np.where(dt_concat.title_kor==t)[0].tolist()\n",
    "    if len(v) > 1:\n",
    "        dt_concat['watcha'][v[1]] = 1\n",
    "        print(t,v,v[1],'2개 이상.')\n",
    "    else:\n",
    "        dt_concat['watcha'][v[0]] = 1\n",
    "        # print(t, v[0], '2개짜리')\n",
    "         \n",
    "    # # if v[1] in v == True:\n",
    "    # #     m +=1\n",
    "    # #     print(v[1])\n",
    "    # # temp3['disney'][v] = 1\n",
    "    # # dt_concat['watcha'][v] = 1\n",
    "    # print(t, v, n)\n",
    "    # n+=1\n",
    "# sum(dt_concat.watcha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 현재 매핑 값 확인.\n",
    "len(dt_concat)\n",
    "list(map(sum, [dt_concat.wavve, dt_concat.watcha, dt_concat.netflix, dt_concat.disney]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_concat = pd.concat([dt_concat, temp2], ignore_index=True, axis=0)\n",
    "len(dt_concat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_concat.drop_duplicates(subset=['title_kor', 'opening_date', 'posterLink'], inplace=True)\n",
    "# len(dt_concat), len(t1), len(temp3), len(temp4)  # (4234, 4, 3270, 968)\n",
    "len(dt_concat), len(t2), len(temp2) # (9224, 574, 5564)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp2.nunique()\n",
    "len(temp2)\n",
    "# sum(dt_concat.watcha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 현재 매핑 값 확인.\n",
    "len(dt_concat)\n",
    "list(map(sum, [dt_concat.wavve, dt_concat.watcha, dt_concat.netflix, dt_concat.disney]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 컨캣 dt와  웨이브(temp1) 붙이고 중복제거."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_concat.reset_index(drop=True, inplace=True)\n",
    "# dt_concat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "copy = dt_concat.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 현재 매핑 값 확인.\n",
    "len(dt_concat)\n",
    "list(map(sum, [dt_concat.wavve, dt_concat.watcha, dt_concat.netflix, dt_concat.disney]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t3 = pd.merge(dt_concat, temp1, on=['title_kor','opening_date','posterLink'], how='inner')\n",
    "len(t3) # 공통영화 5200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(t3.posterLink.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poster_list = t3.posterLink.values\n",
    "poster_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title_list = t3.title_kor.values\n",
    "title_list, type(title_list), len(title_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.where(dt_concat.title_kor==title_list[1])[0]\n",
    "len(np.where(dt_concat.title_kor==title_list[1])[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num = 0\n",
    "for p in poster_list:\n",
    "    i = np.where(dt_concat.posterLink==p)[0][0]\n",
    "    title = dt_concat.title_kor.values[i]\n",
    "    dt_concat['wavve'][i] = 1\n",
    "    \n",
    "    # print\n",
    "    # print(p[0][0])\n",
    "    print(i,title)\n",
    "    num += 1\n",
    "num\n",
    "sum(dt_concat.wavve), num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t3.title_kor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for t in title_list:\n",
    "    v = np.where(dt_concat.title_kor==t)\n",
    "    # temp3['disney'][v] = 1\n",
    "    # dt_concat['watcha'][v] = 1\n",
    "    # dt_concat['wavve'][v] = 1\n",
    "    # print(t, v, (len(v)+97))\n",
    "    print(t, v, (len(v)+97))\n",
    "# sum(temp3.disney)\n",
    "# sum(dt_concat.watcha)\n",
    "sum(dt_concat.wavve)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(range(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for t in title_list:\n",
    "    v = np.where(dt_concat.title_kor==t)[0][0]\n",
    "    # temp3['disney'][v] = 1\n",
    "    dt_concat['watcha'][v] = 1\n",
    "    print(t, v)\n",
    "# sum(temp3.disney)\n",
    "sum(dt_concat.watcha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title_list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = pd.Series(title_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inplace=True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 로우수 적은 디즈니부터 공통된 영화 찾고 & 마킹 >>> 컨캣후 중복값 드랍. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3과 4  (넷플과 디즈니)  \n",
    "\n",
    "t1 = pd.merge(temp3, temp4, on=['title','opening_date'],how='inner')\n",
    "t1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4개의 영화 공통. >>> 매핑 temp3 디즈니에 1 \n",
    "\n",
    "# 인덱스로 값을 찾아 부여하기 위해 \n",
    "length = range(len(t1))\n",
    "for i in length:\n",
    "    for j in range(len(temp3)):\n",
    "        if (temp3.title.values[j] + str(temp3.opening_date.values[j]) == t1.title.values[i] + str(t1.opening_date.values[i])):\n",
    "            temp3.m_disney[j] = 1  # temp3에 디즈니 매핑\n",
    "            print(i), print(j)\n",
    "\n",
    "print(\"=== \"+ str(sum(temp3.m_disney[:]))+\" 개의 공통 영화 매핑 완료 ===\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 컨캣 후 드랍할것 # 색인을 위해 일부러 인덱스는 남김\n",
    "dt_concat = pd.concat([temp3, temp4], axis=0)\n",
    "len(dt_concat) , len(temp3), len(temp4) # 3390 + 969 = 4359"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 중복값 체크후 없으므로 드랍따로 없음\n",
    "dt_concat.duplicated().sum()   # >>> 0\n",
    "# 공통된 4개 제거된 숫자 , inplace=None 이라 데이터 변화 없음. \n",
    "len(dt_concat.drop_duplicates(subset=['title', 'opening_date']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_concat.columns\n",
    "# sum(dt_concat.m_netflix)  # 3390\n",
    "# sum(dt_concat.m_disney)   # 973\n",
    "\n",
    "# 중복 제거전 개수파악을 해서.. 공통 4개가 더 프러스 됐구나... 이해 완료."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_num_dt = dt_concat[dt_concat.columns[-4:]]\n",
    "sum(test_num_dt.values) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 검출\n",
    "\n",
    "num = 0\n",
    "for i in test_num_dt.index:\n",
    "    if sum(test_num_dt.values[i]) == 2:\n",
    "        num = num + 1\n",
    "print(num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_concat.reset_index(inplace=True, drop=True)\n",
    "dt_concat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# copy = dt_concat.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- dt_concat index 바로 잡고. temp2 붙이기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t2 = pd.merge(dt_concat, temp2, \n",
    "    on=['title', 'opening_date'], how='inner')\n",
    "# t2.head()\n",
    "len(t2) # 중복영화 697개"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 697개의 영화 공통. >>> 매핑 dt_concat m_왓챠에 1 \n",
    "\n",
    "# 인덱스로 값을 찾아 부여하기 위해 \n",
    "length = range(len(t2))\n",
    "for i in length:\n",
    "    for j in range(len(dt_concat)):\n",
    "        if (dt_concat.title.values[j] + str(dt_concat.opening_date.values[j]) == t2.title.values[i] + str(t2.opening_date.values[i])):\n",
    "            # dt_concat.m_disney[j] = 1  # dt_concat에 디즈니 매핑\n",
    "            dt_concat.m_wacha[j] = 1\n",
    "            print(i), print(j)\n",
    "\n",
    "print(\"=== \"+ str(sum(dt_concat.m_wacha[:]))+\" 개의 공통 영화 매핑 완료 ===\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(dt_concat.m_wacha) # 697 매핑 확인\n",
    "# len(dt_concat) # 3 + 4 후 중복제거  4359row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 컨캣 후 드랍할것 # 색인을 위해 일부러 인덱스는 남김\n",
    "dt_concat = pd.concat([dt_concat, temp2], axis=0)\n",
    "len(dt_concat) , len(temp2), 4359  # 5537 + 4359 = 9896"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 드랍 # 중복값 없으므로 드랍 없음.\n",
    "dt_concat.duplicated().sum()  # >>> 0\n",
    "dt_concat.title.duplicated().sum()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 중복값 체크후 없으므로 드랍따로 없음\n",
    "dt_concat.duplicated().sum()   # >>> 0\n",
    "# 공통된 697개 제거된 숫자 , inplace=None 이라 데이터 변화 없음. \n",
    "len(dt_concat.drop_duplicates(subset=['title', 'opening_date']))\n",
    "# 9196 + 697 = 9893 row 인데 ... 3개가 어디로 갔지? 제목+개봉일 도 키가 될순 없네. >>> 9896이 드랍전이므로, 디즈니의 중복값 때문에 3개 더 나옴.\n",
    "# 같은해 같은이름으로 다른영화가 개봉할 수 있으니. >>> 없는것으로 확인!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_concat.drop_duplicates(inplace=True, subset=['title', 'opening_date'])\n",
    "len(dt_concat)\n",
    "dt_concat.reset_index(inplace=True, drop=True)\n",
    "dt_concat.tail(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_concat.columns\n",
    "sum(dt_concat.m_netflix)  # 3390 >>> 3390\n",
    "sum(dt_concat.m_disney)   # 973 >>> 969 \n",
    "# 중복제목이 다수일때 듀플리케이트가 \n",
    "# 하나가 아니라 여러개를 버려서 개수차이가 난다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 검출\n",
    "\n",
    "test_num_dt = dt_concat[dt_concat.columns[-4:]]\n",
    "sum(test_num_dt.values) \n",
    "\n",
    "num = 0\n",
    "num3 = 0\n",
    "for i in test_num_dt.index:\n",
    "    if sum(test_num_dt.values[i]) == 2:\n",
    "        num += 1\n",
    "    elif sum(test_num_dt.values[i])==3:\n",
    "        num3 += 1\n",
    "\n",
    "print(num), print(num3)\n",
    "\n",
    "# 697 개가 아니라 698개인 걸로 보아. 3짜리 매핑된게 하나 있나보다.\n",
    "# 3짜리 1개 검출. 인정.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "copy = dt_concat.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- dt_concat index 바로 잡고. temp1 붙이기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t3 = pd.merge(dt_concat, temp1,\n",
    "        on=['title', 'opening_date'], how='inner')\n",
    "len(t3) # 중복영화 5222\n",
    "# t3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5222 개의 영화 공통. >>> 매핑 dt_concat m_웨이브에 1 \n",
    "\n",
    "# 인덱스로 값을 찾아 부여하기 위해 \n",
    "length = range(len(t3))\n",
    "for i in length:\n",
    "    for j in range(len(dt_concat)):\n",
    "        if (dt_concat.title.values[j] + str(dt_concat.opening_date.values[j]) == t3.title.values[i] + str(t3.opening_date.values[i])):\n",
    "            # dt_concat.m_disney[j] = 1  # dt_concat에 디즈니 매핑 (넷플도 매핑되어있음.)\n",
    "            # dt_concat.m_wacha[j] = 1   # dt_concat에 왓챠 매핑.\n",
    "            dt_concat.m_wavve[j] = 1\n",
    "\n",
    "            print(i), print(j)\n",
    "\n",
    "print(\"=== \"+ str(sum(dt_concat.m_wavve[:]))+\" 개의 공통 영화 매핑 완료 ===\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(dt_concat.m_wavve) # 5222개 매핑\n",
    "sum(dt_concat.m_wacha) # 5537개 매핑\n",
    "sum(dt_concat.m_netflix) # 3390개 매핑\n",
    "sum(dt_concat.m_disney) # 969개 매핑\n",
    "list(map(len, [temp1, temp2, temp3, temp4]))  # 매핑 개수는 결과적으로 잘 맞는듯 합니다. \n",
    "# 웨이브는 중복 확인 후 한번더 체크해 볼게요. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# copy = dt_concat.copy()\n",
    "len(dt_concat) # 9196 중복제거 전 현상태.\n",
    "# 9,373 개 영상 정렬 기준 Popularity // 저스트와치 0329 기준\n",
    "# 현재 저스트와치 디즈니, 넷플, 왓챠 선택시 9373개 나오는데\n",
    "# 각 temp에서 제목, 시놉 없는것 버린거 감안하면. 200개 이내로 잃어버린 상황이네요. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 최종 중복 제거후 길이 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 컨캣 후 드랍할것 # 색인을 위해 일부러 인덱스는 남김\n",
    "dt_concat = pd.concat([dt_concat, temp1], axis=0)\n",
    "len(dt_concat) , len(temp1), # 10746 + 9196 = 19942"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_concat.duplicated().sum() # 중복값 없음. 드랍없음.\n",
    "dt_concat.title.duplicated().sum() # 같은 영화제목은 5491개나 있는 상황이네요. 중복제거후 한번더 확인함. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 14720 + 5222 = 19942  // \n",
    "# 중복제거후 로우수 + 같은 영화로 웨이브 매핑 수 = 중복전 컨켓테이블 로우수 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(dt_concat.drop_duplicates(subset=['title', 'opening_date']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inplace\n",
    "dt_concat.drop_duplicates(inplace=True, subset=['title', 'opening_date'])\n",
    "len(dt_concat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_concat.reset_index(inplace=True, drop=True)\n",
    "dt_concat.tail(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 검출\n",
    "\n",
    "test_num_dt = dt_concat[dt_concat.columns[-4:]]\n",
    "sum(test_num_dt.values) \n",
    "\n",
    "num = 0 # 2에 해당.\n",
    "num3 = 0 # 3에 해당.\n",
    "num4 = 0 # 4에 해당.\n",
    "for i in test_num_dt.index:\n",
    "    if sum(test_num_dt.values[i]) == 2:\n",
    "        num += 1\n",
    "    elif sum(test_num_dt.values[i])==3:\n",
    "        num3 += 1\n",
    "    elif sum(test_num_dt.values[i])==4:\n",
    "        num4 += 1 \n",
    "        # print(str(test_num_dt.index[i])+\"4개 당첨\")\n",
    "\n",
    "print(num), print(num3), print(num4)\n",
    "\n",
    "# 4개 당첨된놈 찾아야지?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3개 붙이고 인덱스 조정 후 검출한 결과가 아래일때 90개 가량 소실. 타이틀 + 개봉일로는 중복검출 완전하지 않네.\n",
    "    # 2개 ott 매핑 698 \n",
    "    # 3개 ott 매핑 1   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "copy2 = dt_concat.copy()\n",
    "copy2.to_csv('3rd_concat.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_concat.sort_values(by=['opening_date'], ascending=False, inplace=True, ignore_index=True)\n",
    "dt_concat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 14,991 개 영상 정렬 기준 Popularity  \n",
    "# OTT 4개 선택시 위와 같은데 14720 개로 셋팅. 개봉년도 2022가 위에 가도록 소팅. index 초기화 했으므로 \n",
    "# 이 df 를 최종으로 쓴다고 할시 인덱스를 id로 하여 키값으로 활용가능\n",
    "dt_concat.duplicated().sum() # 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_concat.to_csv('movie_total_220330.csv', index=False)\n",
    "# dt_concat.to_csv('index_non_movie_total_220330.csv', index=False)\n",
    "dt_concat.to_json(r'.movie_total_220330.json', orient='records', force_ascii=False, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = dt_concat.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()\n",
    "# 오프닝 데이트 인트로 바꿔줄 필요 있으면 후처리.\n",
    "# 포스터링크 날린부분 필요하면 후처리."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(df.m_wavve) # >>> 10746 소실 없음. \n",
    "sum(df.m_wacha) # >>> 5537 소실없음. \n",
    "sum(df.m_netflix) # >>> 3390 소실 없음.\n",
    "sum(df.m_disney) # >>> 969 소실 없음.\n",
    "list(map(len, [temp1, temp2, temp3, temp4]))\n",
    "# 매핑 잘 맞네요!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###########\n",
    "# 기존 제목, 시놉을 드랍한 상태로 시작했으니 처리된 결과를 각각 개수로 확인해 보면, \n",
    "\n",
    "\n",
    "# ott    수집로우 > 제목,시놉처리후 > 매핑후(중복제거)\n",
    " \n",
    "# 웨이브  10780   >      10747      >     10746 1개?\n",
    "# 와챠    5591    >      5537       >     5537  \n",
    "# 넷플릭스 3390   >      3390       >     3390\n",
    "# 디즈니   978    >      969        >     969\n",
    "\n",
    "############"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4 > 3 > 2 중요도 순으로 확인작업. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_li = ['m_wavve', 'm_wacha', 'm_netflix', 'm_disney']\n",
    "count_dt = df[col_li]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(count_dt.loc[:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_dt.values[11917]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ott4_title = []\n",
    "idx = range(len(count_dt))\n",
    "for i in idx:\n",
    "    # print(i)\n",
    "    if (sum(count_dt.loc[i]) == 4):\n",
    "        print(f\"인덱스는 : {i}\")\n",
    "        print(f\"영화제목 : {df.title[i]}\")\n",
    "        print(f\"매핑 : {count_dt.values[i]}\")\n",
    "        ott4_title.append([ df.title[i],count_dt.values[i], i])\n",
    "    # (sum(count_dt[col_li][i]) == 4)\n",
    "\n",
    "print(\"================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ott4_title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num = 0\n",
    "ott3_title = []\n",
    "for i in idx:\n",
    "    \n",
    "    if (sum(count_dt.loc[i]) == 3):\n",
    "        print(f\"인덱스는 : {i}\") , \n",
    "        print(f\"영화제목 : {df.title[i]}\"), \n",
    "        print(f\"매핑 : {count_dt.values[i]}\")\n",
    "        num +=1\n",
    "        ott3_title.append([ df.title[i],count_dt.values[i], i])        \n",
    "  \n",
    "print(\"================================\")\n",
    "print(f\"총 개수 : {num}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num = 0\n",
    "ott2_title = []\n",
    "for i in idx:\n",
    "    \n",
    "    if (sum(count_dt.loc[i]) == 2):\n",
    "        print(f\"인덱스는 : {i}\") , \n",
    "        print(f\"영화제목 : {df.title[i]}\"), \n",
    "        print(f\"매핑 : {count_dt.values[i]}\")\n",
    "        num +=1\n",
    "        ott2_title.append([ df.title[i],count_dt.values[i], i])\n",
    "  \n",
    "print(\"================================\")\n",
    "print(f\"총 개수 : {num}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num = 0\n",
    "ott1_title = []\n",
    "for i in idx:\n",
    "    \n",
    "    if (sum(count_dt.loc[i]) == 1):\n",
    "        print(f\"인덱스는 : {i}\") , \n",
    "        print(f\"영화제목 : {df.title[i]}\"), \n",
    "        print(f\"매핑 : {count_dt.values[i]}\")\n",
    "        num +=1\n",
    "        ott1_title.append([ df.title[i],count_dt.values[i], i])\n",
    "  \n",
    "print(\"================================\")\n",
    "print(f\"총 개수 : {num}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ott4_title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ott3_title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ott2_title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ott1_title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np #어레이 저장.\n",
    "np.save(r'./save/ott1_title.npy', ott1_title)\n",
    "np.save(r'./save/ott2_title.npy', ott2_title)\n",
    "np.save(r'./save/ott3_title.npy', ott3_title)\n",
    "np.save(r'./save/ott4_title.npy', ott4_title)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "0ded29b58bc560b714828df704c6cb5a38d3bf429cb4a866f4958899775cbcf6"
  },
  "kernelspec": {
   "display_name": "Python 3.7.1 64-bit ('venv': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
